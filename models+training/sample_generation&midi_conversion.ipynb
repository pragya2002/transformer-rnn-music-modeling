{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRkUxc68oDGn",
        "outputId": "19041330-4e7d-47fc-a80b-55b77d87dcc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJKEErCXoRoX",
        "outputId": "2bab109e-7d42-4efa-db40-df29fc2dd9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['vocab.json', 'train_ids.npy', 'test_ids.npy', 'val_ids.npy']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/music-project-ml-tokenized\"\n",
        "print(os.listdir(data_dir))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IkmGP-yGUD6K"
      },
      "outputs": [],
      "source": [
        "combined_ckpt_path = \"/content/drive/MyDrive/music-project-ml-results/best_xl_full_checkpoint.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KjZJDTg8UXZ2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class GPTConfig:\n",
        "    def __init__(self,\n",
        "                 vocab_size: int,\n",
        "                 block_size: int,\n",
        "                 n_layer: int,\n",
        "                 n_head: int,\n",
        "                 n_embd: int,\n",
        "                 dropout: float = 0.1):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.block_size = block_size\n",
        "        self.n_layer = n_layer\n",
        "        self.n_head = n_head\n",
        "        self.n_embd = n_embd\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.n_head = config.n_head\n",
        "        self.head_dim = config.n_embd // config.n_head\n",
        "\n",
        "        self.qkv = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.attn_drop = nn.Dropout(config.dropout)\n",
        "        self.resid_drop = nn.Dropout(config.dropout)\n",
        "\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "            .view(1, 1, config.block_size, config.block_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "\n",
        "        qkv = self.qkv(x)  # (B, T, 3*C)\n",
        "        q, k, v = qkv.split(C, dim=2)\n",
        "\n",
        "        q = q.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        att = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)  # (B, nh, T, T)\n",
        "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float(\"-inf\"))\n",
        "        att = torch.softmax(att, dim=-1)\n",
        "        att = self.attn_drop(att)\n",
        "\n",
        "        y = att @ v  # (B, nh, T, hd)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "\n",
        "        y = self.resid_drop(self.proj(y))\n",
        "        return y\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
        "        self.fc2 = nn.Linear(4 * config.n_embd, config.n_embd)\n",
        "        self.act = nn.GELU()\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.token_embed = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.pos_embed   = nn.Embedding(config.block_size, config.n_embd)\n",
        "        self.drop = nn.Dropout(config.dropout)\n",
        "\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
        "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.size()\n",
        "        assert T <= self.config.block_size\n",
        "\n",
        "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device).unsqueeze(0)\n",
        "        tok_emb = self.token_embed(idx)        # (B, T, C)\n",
        "        pos_emb = self.pos_embed(pos)          # (1, T, C)\n",
        "        x = self.drop(tok_emb + pos_emb)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)  # (B, T, vocab_size)\n",
        "\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            B, T, V = logits.shape\n",
        "            logits_flat = logits.view(B*T, V)\n",
        "            targets_flat = targets.view(B*T)\n",
        "            loss = nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPg9tdc5Un-_",
        "outputId": "cefb5115-e44e-4ab3-f929-55cc9d16bba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "with open(\"/content/drive/MyDrive/music-project-ml-tokenized/vocab.json\", \"r\") as f:\n",
        "    vocab = json.load(f)\n",
        "\n",
        "# char -> int\n",
        "stoi = vocab[\"stoi\"]\n",
        "\n",
        "# raw itos may be dict with string keys or a list\n",
        "raw_itos = vocab[\"itos\"]\n",
        "if isinstance(raw_itos, dict):\n",
        "    # keys are strings like \"0\", \"1\", ..., convert to int\n",
        "    itos = {int(k): v for k, v in raw_itos.items()}\n",
        "else:\n",
        "    # if it's a list, index is already the id\n",
        "    itos = {i: ch for i, ch in enumerate(raw_itos)}\n",
        "\n",
        "vocab_size = len(stoi)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "def encode(text: str) -> np.ndarray:\n",
        "    \"\"\"String -> array of token ids.\"\"\"\n",
        "    return np.array([stoi[ch] for ch in text if ch in stoi], dtype=np.int64)\n",
        "\n",
        "def decode(ids) -> str:\n",
        "    \"\"\"Iterable of token ids -> string.\"\"\"\n",
        "    return \"\".join(itos[int(i)] for i in ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuk23be0USfi",
        "outputId": "fcfc2b1b-5c00-4ff2-ad26-9c3105eb3391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loaded config: {'n_layer': 20, 'n_head': 8, 'n_embd': 640}\n",
            "Model loaded for sampling.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "ckpt = torch.load(\"/content/drive/MyDrive/music-project-ml-results/best_xl_weights.pt\",\n",
        "                  map_location=device)\n",
        "cfg = ckpt[\"config\"]\n",
        "print(\"Loaded config:\", cfg)\n",
        "\n",
        "model = GPTModel(\n",
        "    GPTConfig(\n",
        "        vocab_size=vocab_size,\n",
        "        block_size=256,\n",
        "        n_layer=cfg[\"n_layer\"],\n",
        "        n_head=cfg[\"n_head\"],\n",
        "        n_embd=cfg[\"n_embd\"],\n",
        "        dropout=0.0,  # no dropout at sampling\n",
        "    )\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded for sampling.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N48BwRO6VPS3",
        "outputId": "d51e75ed-1635-471f-fe15-33fe0b5c6ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  abcm2ps timidity | pmidi postscript-viewer\n",
            "The following NEW packages will be installed:\n",
            "  abcmidi\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 306 kB of archives.\n",
            "After this operation, 868 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 abcmidi amd64 20220218+ds1-1 [306 kB]\n",
            "Fetched 306 kB in 1s (209 kB/s)\n",
            "Selecting previously unselected package abcmidi.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../abcmidi_20220218+ds1-1_amd64.deb ...\n",
            "Unpacking abcmidi (20220218+ds1-1) ...\n",
            "Setting up abcmidi (20220218+ds1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y abcmidi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ayKrW5OKVizm"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate(model, input_ids, max_new_tokens=2000, temperature=1.0, top_k=50):\n",
        "    model.eval()\n",
        "    for _ in range(max_new_tokens):\n",
        "        input_crop = input_ids[:, -model.config.block_size:]\n",
        "        logits, _ = model(input_crop, None)  # (1, T, vocab)\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "\n",
        "        if top_k is not None:\n",
        "            v, ix = torch.topk(logits, top_k)\n",
        "            logits_filtered = torch.full_like(logits, -1e10)\n",
        "            logits_filtered.scatter_(1, ix, v)\n",
        "            logits = logits_filtered\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        next_id = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        input_ids = torch.cat([input_ids, next_id], dim=1)\n",
        "\n",
        "    return input_ids[0].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_85WU3PU4_O",
        "outputId": "c95d39eb-fb04-4ac3-8814-3c9070b4f515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 1 ===\n",
            "  -> MIDI OK (#1) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_1.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 2 ===\n",
            "  -> MIDI OK (#2) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_2.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 3 ===\n",
            "  -> MIDI OK (#3) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_3.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 4 ===\n",
            "  -> MIDI OK (#4) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_4.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 5 ===\n",
            "  -> MIDI OK (#5) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_5.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 6 ===\n",
            "  -> MIDI OK (#6) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_6.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 7 ===\n",
            "  -> MIDI OK (#7) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_7.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 8 ===\n",
            "  -> MIDI OK (#8) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_8.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 9 ===\n",
            "  -> MIDI OK (#9) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_9.mid\n",
            "\n",
            "=== UNCONDITIONAL ATTEMPT 10 ===\n",
            "  -> MIDI OK (#10) saved to /content/drive/MyDrive/music-project-ml-results/unconditional_midis/uncond_success_10.mid\n",
            "\n",
            "=============== DONE GENERATING UNCONDITIONAL ===============\n",
            "Generated 10 MIDI files after 10 attempts.\n",
            "ABC stored in:  /content/drive/MyDrive/music-project-ml-results/unconditional_abc_samples\n",
            "MIDI stored in: /content/drive/MyDrive/music-project-ml-results/unconditional_midis\n",
            "\n",
            "Found 10 ABC files in: /content/drive/MyDrive/music-project-ml-results/unconditional_abc_samples\n",
            "Syntactically valid ABC: 10/10 (100.0%)\n",
            "Successful ABC → MIDI:  10/10 (100.0%)\n",
            "MIDI success among valid ABC: 10/10 (100.0%)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import random\n",
        "import torch\n",
        "import glob\n",
        "\n",
        "# ================================================================\n",
        "# 0. PARAMETERS\n",
        "# ================================================================\n",
        "\n",
        "MAX_BARS = 64                      # ~1 minute of music\n",
        "TARGET_MIDI = 10                   # number of MIDI files to collect\n",
        "MAX_ATTEMPTS = 40                 # stop after this many failures\n",
        "\n",
        "abc_dir = \"/content/drive/MyDrive/music-project-ml-results/unconditional_abc_samples\"\n",
        "midi_dir = \"/content/drive/MyDrive/music-project-ml-results/unconditional_midis\"\n",
        "\n",
        "os.makedirs(abc_dir, exist_ok=True)\n",
        "os.makedirs(midi_dir, exist_ok=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ================================================================\n",
        "# 1. Cleaning utilities (same as conditional version)\n",
        "# ================================================================\n",
        "\n",
        "HEADER_PREFIXES = (\"X:\", \"T:\", \"M:\", \"L:\", \"K:\", \"Q:\", \"V:\", \"C:\", \"R:\")\n",
        "\n",
        "def is_header_line(line: str) -> bool:\n",
        "    s = line.lstrip()\n",
        "    return any(s.startswith(p) for p in HEADER_PREFIXES)\n",
        "\n",
        "def has_header(lines, prefix: str) -> bool:\n",
        "    return any(line.lstrip().startswith(prefix) for line in lines)\n",
        "\n",
        "def has_pitch_chars(line: str) -> bool:\n",
        "    return any(ch in \"ABCDEFGabcdefg\" for ch in line)\n",
        "\n",
        "def clean_abc(text: str) -> str:\n",
        "    cleaned = []\n",
        "    for line in text.splitlines():\n",
        "        s = line.strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        if s.startswith(\"%\"):\n",
        "            continue\n",
        "        if is_header_line(s):\n",
        "            cleaned.append(s)\n",
        "            continue\n",
        "        if not has_pitch_chars(s):\n",
        "            continue\n",
        "        cleaned.append(s)\n",
        "    return \"\\n\".join(cleaned)\n",
        "\n",
        "def add_minimal_header(body: str,\n",
        "                       index=1,\n",
        "                       title=\"Generated Tune\",\n",
        "                       default_meter=\"4/4\",\n",
        "                       default_key=\"C\"):\n",
        "    lines = [ln for ln in body.splitlines() if ln.strip()]\n",
        "    final = []\n",
        "    if not has_header(lines, \"X:\"):\n",
        "        final.append(f\"X:{index}\")\n",
        "    if not has_header(lines, \"T:\"):\n",
        "        final.append(f\"T:{title}\")\n",
        "    if not has_header(lines, \"M:\"):\n",
        "        final.append(f\"M:{default_meter}\")\n",
        "    if not has_header(lines, \"K:\"):\n",
        "        final.append(f\"K:{default_key}\")\n",
        "    final.extend(lines)\n",
        "    return \"\\n\".join(final) + \"\\n\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2. NEW: truncate ABC after N bars (approx 1 minute)\n",
        "# ================================================================\n",
        "\n",
        "def truncate_abc_by_bars(abc_text: str, max_bars: int = 64) -> str:\n",
        "    lines = abc_text.splitlines()\n",
        "\n",
        "    header_lines = []\n",
        "    body_lines = []\n",
        "    in_header = True\n",
        "\n",
        "    for ln in lines:\n",
        "        if in_header and is_header_line(ln):\n",
        "            header_lines.append(ln)\n",
        "        else:\n",
        "            in_header = False\n",
        "            body_lines.append(ln)\n",
        "\n",
        "    truncated_body = []\n",
        "    bar_count = 0\n",
        "\n",
        "    for ln in body_lines:\n",
        "        current = []\n",
        "        for ch in ln:\n",
        "            if ch == \"|\":\n",
        "                bar_count += 1\n",
        "                if bar_count > max_bars:\n",
        "                    break\n",
        "            current.append(ch)\n",
        "        truncated_body.append(\"\".join(current))\n",
        "        if bar_count > max_bars:\n",
        "            break\n",
        "\n",
        "    return \"\\n\".join(header_lines + truncated_body) + \"\\n\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 3. Use abc2midi to test validity or convert to MIDI\n",
        "# ================================================================\n",
        "\n",
        "def abc2midi_ok(abc_path: str, midi_path: str | None = None) -> bool:\n",
        "    cmd = [\"abc2midi\", abc_path]\n",
        "    if midi_path is None:\n",
        "        cmd += [\"-o\", os.devnull]\n",
        "    else:\n",
        "        cmd += [\"-o\", midi_path]\n",
        "\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        errors=\"ignore\",\n",
        "    )\n",
        "    return result.returncode == 0\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 4. UNCONDITIONAL GENERATION LOOP (NO PREFIX)\n",
        "# ================================================================\n",
        "\n",
        "success_count = 0\n",
        "attempt = 0\n",
        "\n",
        "while success_count < TARGET_MIDI and attempt < MAX_ATTEMPTS:\n",
        "    attempt += 1\n",
        "    print(f\"\\n=== UNCONDITIONAL ATTEMPT {attempt} ===\")\n",
        "\n",
        "    # 1) Generate random seed token\n",
        "    seed = torch.randint(0, vocab_size, (1, 1), device=device)\n",
        "    out_ids = generate(model, seed, max_new_tokens=1200, temperature=0.9)\n",
        "    raw_text = decode(out_ids)\n",
        "\n",
        "    # 2) Clean ABC\n",
        "    cleaned = clean_abc(raw_text)\n",
        "\n",
        "    # 3) Add headers\n",
        "    final_abc = add_minimal_header(\n",
        "        cleaned,\n",
        "        index=attempt,\n",
        "        title=f\"Uncond Sample {attempt}\",\n",
        "        default_meter=\"4/4\",\n",
        "        default_key=\"C\"\n",
        "    )\n",
        "\n",
        "    # 4) TRUNCATE to 1 minute using bar counting\n",
        "    final_abc = truncate_abc_by_bars(final_abc, max_bars=MAX_BARS)\n",
        "\n",
        "    # Save ABC\n",
        "    abc_path = os.path.join(abc_dir, f\"uncond_attempt_{attempt}.abc\")\n",
        "    with open(abc_path, \"w\") as f:\n",
        "        f.write(final_abc)\n",
        "\n",
        "    # 5) Convert using abc2midi\n",
        "    midi_path = os.path.join(midi_dir, f\"uncond_success_{success_count+1}.mid\")\n",
        "\n",
        "    if abc2midi_ok(abc_path, midi_path):\n",
        "        success_count += 1\n",
        "        print(f\"  -> MIDI OK (#{success_count}) saved to {midi_path}\")\n",
        "    else:\n",
        "        print(\"  -> abc2midi FAILED (syntax or conversion error)\")\n",
        "\n",
        "print(\"\\n=============== DONE GENERATING UNCONDITIONAL ===============\")\n",
        "print(f\"Generated {success_count} MIDI files after {attempt} attempts.\")\n",
        "print(f\"ABC stored in:  {abc_dir}\")\n",
        "print(f\"MIDI stored in: {midi_dir}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 5. REPORT VALIDITY & CONVERSION RATES\n",
        "# ================================================================\n",
        "\n",
        "abc_files = sorted(glob.glob(os.path.join(abc_dir, \"*.abc\")))\n",
        "total_abc = len(abc_files)\n",
        "\n",
        "print(f\"\\nFound {total_abc} ABC files in: {abc_dir}\")\n",
        "\n",
        "# A) syntactic validity\n",
        "valid_count = sum(1 for f in abc_files if abc2midi_ok(f, midi_path=None))\n",
        "valid_pct = 100 * valid_count / total_abc if total_abc else 0\n",
        "\n",
        "# B) actual MIDI conversion success\n",
        "midi_files = [x for x in os.listdir(midi_dir) if x.endswith(\".mid\")]\n",
        "total_midi = len(midi_files)\n",
        "midi_pct = 100 * total_midi / total_abc if total_abc else 0\n",
        "\n",
        "print(f\"Syntactically valid ABC: {valid_count}/{total_abc} ({valid_pct:.1f}%)\")\n",
        "print(f\"Successful ABC → MIDI:  {total_midi}/{total_abc} ({midi_pct:.1f}%)\")\n",
        "\n",
        "if valid_count > 0:\n",
        "    midi_over_valid = 100 * total_midi / valid_count\n",
        "    print(f\"MIDI success among valid ABC: {total_midi}/{valid_count} ({midi_over_valid:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6MQLICWYkw_",
        "outputId": "36f21da5-b499-4569-c22d-0f57e5e40134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== CONDITIONAL ATTEMPT 1 ===\n",
            "  -> abc2midi OK (#1) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_1.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 2 ===\n",
            "  -> abc2midi OK (#2) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_2.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 3 ===\n",
            "  -> abc2midi OK (#3) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_3.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 4 ===\n",
            "  -> abc2midi OK (#4) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_4.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 5 ===\n",
            "  -> abc2midi OK (#5) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_5.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 6 ===\n",
            "  -> abc2midi OK (#6) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_6.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 7 ===\n",
            "  -> abc2midi OK (#7) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_7.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 8 ===\n",
            "  -> abc2midi OK (#8) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_8.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 9 ===\n",
            "  -> abc2midi OK (#9) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_9.mid\n",
            "\n",
            "=== CONDITIONAL ATTEMPT 10 ===\n",
            "  -> abc2midi OK (#10) saved to /content/drive/MyDrive/music-project-ml-results/conditional_midis/cond_success_10.mid\n",
            "\n",
            "================ GENERATION DONE ================\n",
            "Generated 10 MIDI files after 10 attempts.\n",
            "ABC saved in:  /content/drive/MyDrive/music-project-ml-results/conditional_abc_samples\n",
            "MIDI saved in: /content/drive/MyDrive/music-project-ml-results/conditional_midis\n",
            "\n",
            "Found 10 ABC files in /content/drive/MyDrive/music-project-ml-results/conditional_abc_samples\n",
            "Syntactically valid ABC (abc2midi): 10/10 (100.0%)\n",
            "Successful ABC → MIDI (abc2midi): 10/10 (100.0%)\n",
            "MIDI successes among valid ABC: 10/10 (100.0%)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import subprocess\n",
        "import torch\n",
        "import glob\n",
        "\n",
        "# ================================================================\n",
        "# 1. Three prefixes\n",
        "# ================================================================\n",
        "\n",
        "prefix_A = \"\"\"X: X:1759\n",
        "T:F\\\"ur Elise\n",
        "T:Bagatelle No.25 in A, WoO.59\n",
        "C:Ludwig van Beethoven\n",
        "O:Germany\n",
        "Z:Transcribed by Frank Nordberg - http://www.musicaviva.com\n",
        "F:http://abc.musicaviva.com/tunes/beethoven-ludwig-van/be059/be059-pno2.abc\n",
        "V:1 Program 1 0 %Piano\n",
        "V:2 Program 1 0 bass %Piano\n",
        "M:3/8\n",
        "L:1/16\n",
        "Q:3/8=40\n",
        "K:Am\n",
        "V:1\n",
        "e^d|e^deB=dc|A2 z CEA|B2 z E^GB|c2\n",
        "\"\"\"\n",
        "\n",
        "prefix_B = \"\"\"X:670\n",
        "T:Jingle Bells\n",
        "C:James Lord Pierpont, 1857\n",
        "M:2/2\n",
        "R:Reel\n",
        "L:1/4\n",
        "S:Colin Hume's website - chords can also be printed below.\n",
        "Q:1/2=110\n",
        "K:G\n",
        "V:1\n",
        "%%MIDI chordprog 70\n",
        "%%MIDI program 57\n",
        "%%MIDI gchord zzczzzcz\n",
        "\"G\"DB AG | \"/\"D3 D/D/ | \"G\"DB AG | \"C\"E4 | \"Am\"Ec BA | \"D\"F4 | \"D7\"dd cA | \"G\"B4 |\n",
        "\"\"\"\n",
        "\n",
        "prefix_C = \"\"\"X: 3\n",
        "T:Happy Birthday to You\n",
        "M:3/4\n",
        "L:1/8\n",
        "K:G\n",
        "D>D | E2 D2 G2 | F4 D>D | E2 D2 A2 | G4 D>D |\n",
        "\"\"\"\n",
        "\n",
        "prefixes = [prefix_A, prefix_B, prefix_C]\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2. Cleaning + header utilities (no music21 here)\n",
        "# ================================================================\n",
        "\n",
        "HEADER_PREFIXES = (\"X:\", \"T:\", \"M:\", \"L:\", \"K:\", \"Q:\", \"V:\", \"C:\", \"R:\")\n",
        "\n",
        "def is_header_line(line: str) -> bool:\n",
        "    s = line.lstrip()\n",
        "    return any(s.startswith(p) for p in HEADER_PREFIXES)\n",
        "\n",
        "def has_header(lines, prefix: str) -> bool:\n",
        "    return any(line.lstrip().startswith(prefix) for line in lines)\n",
        "\n",
        "def has_pitch_chars(line: str) -> bool:\n",
        "    # Rough heuristic: must contain at least one pitch letter A–G/a–g\n",
        "    return any(ch in \"ABCDEFGabcdefg\" for ch in line)\n",
        "\n",
        "def clean_abc(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Drop empty lines, comments, and lines with no pitch letters.\n",
        "    Keep header lines and musically meaningful lines.\n",
        "    \"\"\"\n",
        "    cleaned = []\n",
        "    for line in text.splitlines():\n",
        "        s = line.strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        if s.startswith(\"%\"):\n",
        "            continue\n",
        "        if is_header_line(s):\n",
        "            cleaned.append(s)\n",
        "            continue\n",
        "        if not has_pitch_chars(s):\n",
        "            continue\n",
        "        cleaned.append(s)\n",
        "    return \"\\n\".join(cleaned)\n",
        "\n",
        "def add_minimal_header(body: str,\n",
        "                       index: int = 1,\n",
        "                       title: str = \"Generated Tune\",\n",
        "                       default_meter: str = \"4/4\",\n",
        "                       default_key: str = \"C\") -> str:\n",
        "    \"\"\"\n",
        "    Ensure X:, T:, M:, K: exist once at the top.\n",
        "    \"\"\"\n",
        "    lines = [ln for ln in body.splitlines() if ln.strip()]\n",
        "    final = []\n",
        "    if not has_header(lines, \"X:\"):\n",
        "        final.append(f\"X:{index}\")\n",
        "    if not has_header(lines, \"T:\"):\n",
        "        final.append(f\"T:{title}\")\n",
        "    if not has_header(lines, \"M:\"):\n",
        "        final.append(f\"M:{default_meter}\")\n",
        "    if not has_header(lines, \"K:\"):\n",
        "        final.append(f\"K:{default_key}\")\n",
        "    final.extend(lines)\n",
        "    return \"\\n\".join(final) + \"\\n\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2b. NEW: Truncate by number of bars (approx \"1 minute\" cap)\n",
        "# ================================================================\n",
        "\n",
        "def truncate_abc_by_bars(abc_text: str, max_bars: int = 64) -> str:\n",
        "    \"\"\"\n",
        "    Keep headers, then truncate the body after at most `max_bars` barlines ('|').\n",
        "    This approximates limiting the musical length to around ~1 minute.\n",
        "    \"\"\"\n",
        "    lines = abc_text.splitlines()\n",
        "\n",
        "    header_lines = []\n",
        "    body_lines = []\n",
        "    in_header = True\n",
        "\n",
        "    for ln in lines:\n",
        "        # Once we hit the first non-header, treat the rest as body\n",
        "        if in_header and is_header_line(ln):\n",
        "            header_lines.append(ln)\n",
        "        else:\n",
        "            in_header = False\n",
        "            body_lines.append(ln)\n",
        "\n",
        "    bar_count = 0\n",
        "    truncated_body_lines = []\n",
        "\n",
        "    for ln in body_lines:\n",
        "        current_line_chars = []\n",
        "        for ch in ln:\n",
        "            if ch == '|':\n",
        "                bar_count += 1\n",
        "                if bar_count > max_bars:\n",
        "                    # Stop including more once we exceed max_bars\n",
        "                    break\n",
        "            current_line_chars.append(ch)\n",
        "        truncated_body_lines.append(\"\".join(current_line_chars))\n",
        "        if bar_count > max_bars:\n",
        "            break\n",
        "\n",
        "    # Reassemble\n",
        "    full_lines = header_lines + truncated_body_lines\n",
        "    # Remove trailing totally-empty lines\n",
        "    full_lines = [l for l in full_lines if l.strip() != \"\"]\n",
        "    return \"\\n\".join(full_lines) + \"\\n\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 3. Conditional generator that randomly chooses a prefix\n",
        "# ================================================================\n",
        "\n",
        "def generate_with_random_prefix(max_len=1200, temperature=0.9):\n",
        "    prefix_text = random.choice(prefixes)\n",
        "    prefix_ids = encode(prefix_text)\n",
        "    input_ids = torch.tensor(prefix_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
        "    out_ids = generate(model, input_ids, max_new_tokens=max_len, temperature=temperature)\n",
        "    return prefix_text, decode(out_ids)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 4. Helper: use abc2midi to test syntax or convert\n",
        "# ================================================================\n",
        "\n",
        "def abc2midi_ok(abc_path: str, midi_path: str | None = None) -> bool:\n",
        "    \"\"\"\n",
        "    Run abc2midi on abc_path.\n",
        "    If midi_path is None, send output to /dev/null (syntax check only).\n",
        "    Returns True iff abc2midi exit code is 0.\n",
        "    \"\"\"\n",
        "    cmd = [\"abc2midi\", abc_path]\n",
        "    if midi_path is None:\n",
        "        cmd += [\"-o\", os.devnull]\n",
        "    else:\n",
        "        cmd += [\"-o\", midi_path]\n",
        "\n",
        "    # text=True but ignore decode errors to avoid UnicodeDecodeError\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        errors=\"ignore\",\n",
        "    )\n",
        "    return result.returncode == 0\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 5. Loop until we get 10 MIDI files (conversion via abc2midi)\n",
        "#    with truncation to ~1 minute via max_bars\n",
        "# ================================================================\n",
        "\n",
        "target_midi = 10\n",
        "max_attempts = 40\n",
        "MAX_BARS = 64   # tweak this if you want shorter/longer pieces\n",
        "\n",
        "abc_dir = \"/content/drive/MyDrive/music-project-ml-results/conditional_abc_samples\"\n",
        "midi_dir = \"/content/drive/MyDrive/music-project-ml-results/conditional_midis\"\n",
        "os.makedirs(abc_dir, exist_ok=True)\n",
        "os.makedirs(midi_dir, exist_ok=True)\n",
        "\n",
        "success_count = 0\n",
        "attempt = 0\n",
        "\n",
        "while success_count < target_midi and attempt < max_attempts:\n",
        "    attempt += 1\n",
        "    print(f\"\\n=== CONDITIONAL ATTEMPT {attempt} ===\")\n",
        "\n",
        "    # 1) Generate conditioned on a random prefix\n",
        "    chosen_prefix, raw = generate_with_random_prefix()\n",
        "\n",
        "    # 2) Clean & add header\n",
        "    cleaned = clean_abc(raw)\n",
        "    final_abc = add_minimal_header(\n",
        "        cleaned,\n",
        "        index=attempt,\n",
        "        title=f\"Conditional Sample {attempt}\",\n",
        "        default_meter=\"4/4\",\n",
        "        default_key=\"C\",\n",
        "    )\n",
        "\n",
        "    # 3) Truncate the music to ~1 minute (by bar count)\n",
        "    final_abc = truncate_abc_by_bars(final_abc, max_bars=MAX_BARS)\n",
        "\n",
        "    # Save ABC (for inspection)\n",
        "    abc_path = os.path.join(abc_dir, f\"cond_attempt_{attempt}.abc\")\n",
        "    with open(abc_path, \"w\") as f:\n",
        "        f.write(final_abc)\n",
        "\n",
        "    # 4) Convert using abc2midi\n",
        "    midi_path = os.path.join(midi_dir, f\"cond_success_{success_count+1}.mid\")\n",
        "    ok = abc2midi_ok(abc_path, midi_path)\n",
        "    if ok:\n",
        "        success_count += 1\n",
        "        print(f\"  -> abc2midi OK (#{success_count}) saved to {midi_path}\")\n",
        "    else:\n",
        "        print(\"  -> abc2midi FAILED (syntax or conversion error)\")\n",
        "\n",
        "print(\"\\n================ GENERATION DONE ================\")\n",
        "print(f\"Generated {success_count} MIDI files after {attempt} attempts.\")\n",
        "print(f\"ABC saved in:  {abc_dir}\")\n",
        "print(f\"MIDI saved in: {midi_dir}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 6. Reporting: syntactically valid % and conversion success %\n",
        "# ================================================================\n",
        "\n",
        "abc_files = sorted(glob.glob(os.path.join(abc_dir, \"*.abc\")))\n",
        "total_abc = len(abc_files)\n",
        "print(f\"\\nFound {total_abc} ABC files in {abc_dir}\")\n",
        "\n",
        "# (a) Syntactic validity via abc2midi to /dev/null\n",
        "valid_count = 0\n",
        "for path in abc_files:\n",
        "    if abc2midi_ok(path, midi_path=None):\n",
        "        valid_count += 1\n",
        "\n",
        "valid_pct = 100.0 * valid_count / total_abc if total_abc > 0 else 0.0\n",
        "print(f\"Syntactically valid ABC (abc2midi): {valid_count}/{total_abc} ({valid_pct:.1f}%)\")\n",
        "\n",
        "# (b) Conversion success: how many .mid actually produced\n",
        "midi_files = [f for f in os.listdir(midi_dir) if f.endswith(\".mid\")]\n",
        "total_midi = len(midi_files)\n",
        "midi_pct = 100.0 * total_midi / total_abc if total_abc > 0 else 0.0\n",
        "print(f\"Successful ABC → MIDI (abc2midi): {total_midi}/{total_abc} ({midi_pct:.1f}%)\")\n",
        "\n",
        "# (c) Optional: among syntactically valid ones, how many produced MIDI\n",
        "midi_over_valid_pct = 100.0 * total_midi / valid_count if valid_count > 0 else 0.0\n",
        "print(f\"MIDI successes among valid ABC: {total_midi}/{valid_count} ({midi_over_valid_pct:.1f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
